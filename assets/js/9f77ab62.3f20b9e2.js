"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[1137],{1532:i=>{i.exports=JSON.parse('{"label":"Vision-Language-Action","permalink":"/New-Physical-AI-and-Humanoid-Robotics/docs/tags/vision-language-action","allTagsPath":"/New-Physical-AI-and-Humanoid-Robotics/docs/tags","count":2,"items":[{"id":"week-11-13/week-11-13","title":"Module 4: Vision-Language-Action (VLA) Systems","description":"Week 11-13 content covering Vision-Language-Action systems, multimodal robotics, LLM planning, and autonomous humanoid implementation","permalink":"/New-Physical-AI-and-Humanoid-Robotics/docs/week-11-13/"},{"id":"week-11-13/vision-language-action-systems","title":"Vision-Language-Action Systems","description":"Understanding Vision-Language-Action (VLA) systems that integrate perception, language understanding, and robotic action","permalink":"/New-Physical-AI-and-Humanoid-Robotics/docs/week-11-13/vision-language-action-systems"}],"unlisted":false}')}}]);