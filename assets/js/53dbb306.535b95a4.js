"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[4082],{8453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>t});var r=i(6540);const s={},a=r.createContext(s);function o(n){const e=r.useContext(a);return r.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function t(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:o(n.components),r.createElement(a.Provider,{value:e},n.children)}},8809:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>a,metadata:()=>t,toc:()=>c});var r=i(4848),s=i(8453);const a={title:"Weeks 6-7: Robot Simulation with Gazebo",description:"Module covering Gazebo simulation environment setup, URDF/SDF formats, physics simulation, sensor simulation, and introduction to Unity for robot visualization",tags:["Gazebo","Unity","Simulation","Robotics","Humanoid","URDF","SDF","Physics"]},o="Weeks 6-7: Robot Simulation with Gazebo",t={id:"week-6-7/week-6-7",title:"Weeks 6-7: Robot Simulation with Gazebo",description:"Module covering Gazebo simulation environment setup, URDF/SDF formats, physics simulation, sensor simulation, and introduction to Unity for robot visualization",source:"@site/docs/week-6-7/week-6-7.md",sourceDirName:"week-6-7",slug:"/week-6-7/",permalink:"/New-Physical-AI-and-Humanoid-Robotics/docs/week-6-7/",draft:!1,unlisted:!1,editUrl:"https://github.com/JaveriaNigar/New-Physical-AI-and-Humanoid-Robotics/docs/week-6-7/week-6-7.md",tags:[{label:"Gazebo",permalink:"/New-Physical-AI-and-Humanoid-Robotics/docs/tags/gazebo"},{label:"Unity",permalink:"/New-Physical-AI-and-Humanoid-Robotics/docs/tags/unity"},{label:"Simulation",permalink:"/New-Physical-AI-and-Humanoid-Robotics/docs/tags/simulation"},{label:"Robotics",permalink:"/New-Physical-AI-and-Humanoid-Robotics/docs/tags/robotics"},{label:"Humanoid",permalink:"/New-Physical-AI-and-Humanoid-Robotics/docs/tags/humanoid"},{label:"URDF",permalink:"/New-Physical-AI-and-Humanoid-Robotics/docs/tags/urdf"},{label:"SDF",permalink:"/New-Physical-AI-and-Humanoid-Robotics/docs/tags/sdf"},{label:"Physics",permalink:"/New-Physical-AI-and-Humanoid-Robotics/docs/tags/physics"}],version:"current",frontMatter:{title:"Weeks 6-7: Robot Simulation with Gazebo",description:"Module covering Gazebo simulation environment setup, URDF/SDF formats, physics simulation, sensor simulation, and introduction to Unity for robot visualization",tags:["Gazebo","Unity","Simulation","Robotics","Humanoid","URDF","SDF","Physics"]}},l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Gazebo Simulation Environment Setup",id:"gazebo-simulation-environment-setup",level:2},{value:"Section 1: Gazebo Simulation Environment Setup",id:"section-1-gazebo-simulation-environment-setup",level:2},{value:"Gazebo Architecture",id:"gazebo-architecture",level:3},{value:"Installation Process Visualization",id:"installation-process-visualization",level:3},{value:"Gazebo World Components",id:"gazebo-world-components",level:3},{value:"Installation and Setup",id:"installation-and-setup",level:3},{value:"Prerequisites",id:"prerequisites",level:4},{value:"Installation Steps",id:"installation-steps",level:4},{value:"Verification",id:"verification",level:3},{value:"Basic Gazebo Concepts",id:"basic-gazebo-concepts",level:3},{value:"World Files",id:"world-files",level:4},{value:"Models",id:"models",level:4},{value:"Sensors",id:"sensors",level:4},{value:"Section 2: URDF and SDF Robot Description Formats",id:"section-2-urdf-and-sdf-robot-description-formats",level:2},{value:"Introduction to URDF and SDF",id:"introduction-to-urdf-and-sdf",level:3},{value:"URDF vs SDF: Key Differences",id:"urdf-vs-sdf-key-differences",level:3},{value:"URDF Structure",id:"urdf-structure",level:3},{value:"SDF Structure",id:"sdf-structure",level:3},{value:"Converting URDF to SDF",id:"converting-urdf-to-sdf",level:3},{value:"Adding Gazebo-Specific Extensions to URDF",id:"adding-gazebo-specific-extensions-to-urdf",level:3},{value:"Section 3: Physics Simulation &amp; Sensor Simulation",id:"section-3-physics-simulation--sensor-simulation",level:2},{value:"Physics Simulation Fundamentals",id:"physics-simulation-fundamentals",level:3},{value:"Core Physics Concepts",id:"core-physics-concepts",level:3},{value:"Time Step Configuration",id:"time-step-configuration",level:4},{value:"Real Time Factor (RTF)",id:"real-time-factor-rtf",level:4},{value:"Solver Parameters",id:"solver-parameters",level:4},{value:"Sensor Simulation Fundamentals",id:"sensor-simulation-fundamentals",level:3},{value:"Adding Noise Models",id:"adding-noise-models",level:3},{value:"LiDAR Sensor Simulation",id:"lidar-sensor-simulation",level:3},{value:"Depth Camera Simulation",id:"depth-camera-simulation",level:3},{value:"IMU Simulation",id:"imu-simulation",level:3},{value:"Section 4: Gazebo Physics, Collisions, Environment Design",id:"section-4-gazebo-physics-collisions-environment-design",level:2},{value:"Physics Simulation Fundamentals",id:"physics-simulation-fundamentals-1",level:3},{value:"Core Physics Concepts",id:"core-physics-concepts-1",level:3},{value:"Time Step Configuration",id:"time-step-configuration-1",level:4},{value:"Real Time Factor (RTF)",id:"real-time-factor-rtf-1",level:4},{value:"Solver Parameters",id:"solver-parameters-1",level:4},{value:"Collision Modeling for Humanoids",id:"collision-modeling-for-humanoids",level:3},{value:"Collision Geometry Selection",id:"collision-geometry-selection",level:4},{value:"Multi-Collision Links",id:"multi-collision-links",level:4},{value:"Contact Stabilization",id:"contact-stabilization",level:4},{value:"Environment Design for Humanoid Robots",id:"environment-design-for-humanoid-robots",level:3},{value:"Creating Human-Scale Environments",id:"creating-human-scale-environments",level:4},{value:"Furniture and Obstacles",id:"furniture-and-obstacles",level:4},{value:"Section 5: Sensor Simulation (LiDAR, Depth, IMU)",id:"section-5-sensor-simulation-lidar-depth-imu",level:2},{value:"Sensor Simulation Fundamentals",id:"sensor-simulation-fundamentals-1",level:3},{value:"Adding Noise Models",id:"adding-noise-models-1",level:3},{value:"LiDAR Simulation in Detail",id:"lidar-simulation-in-detail",level:3},{value:"Depth Camera Simulation for 3D Perception",id:"depth-camera-simulation-for-3d-perception",level:3},{value:"IMU Simulation for Humanoid Balance",id:"imu-simulation-for-humanoid-balance",level:3},{value:"Section 6: Unity Integration for Robot Visualization",id:"section-6-unity-integration-for-robot-visualization",level:2},{value:"Setting Up Unity for Robotics",id:"setting-up-unity-for-robotics",level:3},{value:"Basic Unity-ROS 2 Integration",id:"basic-unity-ros-2-integration",level:3},{value:"Unity for Robot Visualization",id:"unity-for-robot-visualization",level:3},{value:"Section 7: Simulation Best Practices",id:"section-7-simulation-best-practices",level:2},{value:"Performance Optimization",id:"performance-optimization",level:3},{value:"Debugging Techniques",id:"debugging-techniques",level:3},{value:"Validation Techniques",id:"validation-techniques",level:3},{value:"Exercises",id:"exercises",level:2},{value:"Quiz",id:"quiz",level:2},{value:"Reflection",id:"reflection",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.h1,{id:"weeks-6-7-robot-simulation-with-gazebo",children:"Weeks 6-7: Robot Simulation with Gazebo"}),"\n",(0,r.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,r.jsx)(e.p,{children:"By the end of this chapter, students will be able to:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Install and configure Gazebo for robotics simulation"}),"\n",(0,r.jsx)(e.li,{children:"Understand the relationship between URDF and SDF formats"}),"\n",(0,r.jsx)(e.li,{children:"Configure physics simulation parameters for humanoid robots"}),"\n",(0,r.jsx)(e.li,{children:"Simulate various sensors (LiDAR, cameras, IMU) in Gazebo"}),"\n",(0,r.jsx)(e.li,{children:"Develop simulation scenarios for humanoid robot behavior"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"gazebo-simulation-environment-setup",children:"Gazebo Simulation Environment Setup"}),"\n",(0,r.jsx)(e.p,{children:"Gazebo is a powerful physics simulation environment that provides realistic rendering, physics simulation, and sensor simulation capabilities for robotics development. It's widely used in the robotics community for testing algorithms and validating robot behaviors before deploying to physical platforms."}),"\n",(0,r.jsx)(e.p,{children:"For humanoid robotics, Gazebo is particularly valuable due to its accurate physics simulation capabilities, which are essential for testing complex multi-body dynamics, balance control, and interaction with environments designed for humans."}),"\n",(0,r.jsx)(e.h2,{id:"section-1-gazebo-simulation-environment-setup",children:"Section 1: Gazebo Simulation Environment Setup"}),"\n",(0,r.jsx)(e.h3,{id:"gazebo-architecture",children:"Gazebo Architecture"}),"\n",(0,r.jsx)(e.p,{children:"Gazebo operates on a client-server architecture:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Gazebo Server"}),": Handles the physics simulation, sensor simulation, and maintains the state of the world"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Gazebo Client"}),": Provides the graphical user interface for visualization and interaction"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Communication"}),": Server and client communicate via transport mechanisms using message passing"]}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-mermaid",children:"graph TB\r\n    A[Gazebo Client<br/>GUI & Visualization] --\x3e C{Transport Layer}\r\n    B[Gazebo Server<br/>Physics & Simulation] --\x3e C\r\n    C --\x3e D[Plugins & Sensors]\r\n    C --\x3e E[ROS 2 Interface]\r\n    C --\x3e F[World Models]\n"})}),"\n",(0,r.jsx)(e.h3,{id:"installation-process-visualization",children:"Installation Process Visualization"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-mermaid",children:"flowchart LR\r\n    A[Start: Ubuntu 22.04 + ROS 2 Humble] --\x3e B[Add OSRF Repository]\r\n    B --\x3e C[Install Gazebo Garden]\r\n    C --\x3e D[Install ROS 2 Gazebo Packages]\r\n    D --\x3e E[Set Environment Variables]\r\n    E --\x3e F[Verify Installation]\r\n    F --\x3e G{Success?}\r\n    G --\x3e|Yes| H[Ready to Use]\r\n    G --\x3e|No| I[Troubleshoot Issues]\r\n    I --\x3e D\n"})}),"\n",(0,r.jsx)(e.h3,{id:"gazebo-world-components",children:"Gazebo World Components"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-mermaid",children:"graph TB\r\n    A[Gazebo World] --\x3e B[Physics Engine]\r\n    A --\x3e C[Models & Objects]\r\n    A --\x3e D[Lights]\r\n    A --\x3e E[Environment Settings]\r\n\r\n    B --\x3e B1[Gravity]\r\n    B --\x3e B2[Time Step]\r\n    B --\x3e B3[Solver Parameters]\r\n\r\n    C --\x3e C1[Static Models]\r\n    C --\x3e C2[Dynamic Models]\r\n    C --\x3e C3[Robots]\r\n\r\n    D --\x3e D1[Ambient Light]\r\n    D --\x3e D2[Directional Light]\r\n    D --\x3e D3[Point Lights]\r\n\r\n    E --\x3e E1[Textures]\r\n    E --\x3e E2[Sky Settings]\r\n    E --\x3e E3[Atmosphere Effects]\n"})}),"\n",(0,r.jsx)(e.h3,{id:"installation-and-setup",children:"Installation and Setup"}),"\n",(0,r.jsx)(e.h4,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,r.jsx)(e.p,{children:"Before installing Gazebo, ensure you have:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Ubuntu 22.04 LTS or later"}),"\n",(0,r.jsx)(e.li,{children:"ROS 2 Humble Hawksbill installed"}),"\n",(0,r.jsx)(e.li,{children:"Sufficient hardware resources (recommended: 4GB+ RAM, dedicated GPU)"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"installation-steps",children:"Installation Steps"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"Add the OSRF repository:"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:'sudo apt update && sudo apt install wget\r\nwget https://packages.osrfoundation.org/gazebo.gpg -O /tmp/gazebo.gpg\r\nsudo cp /tmp/gazebo.gpg /usr/share/keyrings/\r\necho "deb [arch=amd64 signed-by=/usr/share/keyrings/gazebo.gpg] http://packages.osrfoundation.org/gazebo/ubuntu-stable jammy main" | sudo tee /etc/apt/sources.list.d/gazebo.list > /dev/null\r\nsudo apt update\n'})}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"Install Gazebo Garden:"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"sudo apt install gz-garden\n"})}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"Install ROS 2 Gazebo packages (ros-gz bridge):"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"sudo apt install ros-humble-gazebo-ros-pkgs ros-humble-gazebo-ros2-control\n"})}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Set up environment variables:"}),"\r\nAdd these lines to your ",(0,r.jsx)(e.code,{children:"~/.bashrc"}),":"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"export GZ_VERSION=garden\r\nexport GZ_SIM_SYSTEM_PLUGIN_PATH=/usr/lib/x86_64-linux-gnu/gz-sim-${GZ_VERSION}\r\nexport GZ_SIM_RESOURCE_PATH=/usr/share/gz-sim-${GZ_VERSION}\r\nexport GZ_SIM_SYSTEM_PLUGIN_PATH=/usr/lib/x86_64-linux-gnu/gz-sim-${GZ_VERSION}\n"})}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"Reload your environment:"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"source ~/.bashrc\n"})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"verification",children:"Verification"}),"\n",(0,r.jsx)(e.p,{children:"Test the installation by launching Gazebo:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"gz sim\n"})}),"\n",(0,r.jsx)(e.p,{children:"If Gazebo launches successfully with the default empty world, the installation was successful."}),"\n",(0,r.jsx)(e.h3,{id:"basic-gazebo-concepts",children:"Basic Gazebo Concepts"}),"\n",(0,r.jsx)(e.h4,{id:"world-files",children:"World Files"}),"\n",(0,r.jsxs)(e.p,{children:["Gazebo worlds are defined using SDF (Simulation Description Format) files with ",(0,r.jsx)(e.code,{children:".sdf"})," or ",(0,r.jsx)(e.code,{children:".world"})," extensions. These files define:"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"The physics engine parameters"}),"\n",(0,r.jsx)(e.li,{children:"The world environment (terrain, lighting, etc.)"}),"\n",(0,r.jsx)(e.li,{children:"Initial robot poses"}),"\n",(0,r.jsx)(e.li,{children:"Static objects and obstacles"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"models",children:"Models"}),"\n",(0,r.jsx)(e.p,{children:"Gazebo models represent physical objects in the simulation. Models include:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Visual representation"}),"\n",(0,r.jsx)(e.li,{children:"Collision geometry"}),"\n",(0,r.jsx)(e.li,{children:"Physics properties"}),"\n",(0,r.jsx)(e.li,{children:"Sensors"}),"\n",(0,r.jsx)(e.li,{children:"Plugins"}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"sensors",children:"Sensors"}),"\n",(0,r.jsx)(e.p,{children:"Gazebo can simulate various sensors:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Cameras (RGB, depth, stereo)"}),"\n",(0,r.jsx)(e.li,{children:"LiDAR (2D and 3D)"}),"\n",(0,r.jsx)(e.li,{children:"IMU (Inertial Measurement Units)"}),"\n",(0,r.jsx)(e.li,{children:"Force/torque sensors"}),"\n",(0,r.jsx)(e.li,{children:"GPS"}),"\n",(0,r.jsx)(e.li,{children:"Contact sensors"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"section-2-urdf-and-sdf-robot-description-formats",children:"Section 2: URDF and SDF Robot Description Formats"}),"\n",(0,r.jsx)(e.h3,{id:"introduction-to-urdf-and-sdf",children:"Introduction to URDF and SDF"}),"\n",(0,r.jsx)(e.p,{children:"Unified Robot Description Format (URDF) and Simulation Description Format (SDF) are both XML-based formats used to describe robots, but they serve different purposes and have different capabilities. URDF is primarily used in ROS for robot description, while SDF is used in Gazebo for simulation. Understanding both formats and their relationship is crucial for effective robot simulation."}),"\n",(0,r.jsx)(e.p,{children:"URDF is tightly integrated with ROS and is excellent for describing robot kinematics and basic visual/collision properties. SDF, used by Gazebo and Ignition, extends these capabilities with simulation-specific parameters like physics, sensors, and plugins."}),"\n",(0,r.jsx)(e.h3,{id:"urdf-vs-sdf-key-differences",children:"URDF vs SDF: Key Differences"}),"\n",(0,r.jsxs)(e.table,{children:[(0,r.jsx)(e.thead,{children:(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.th,{children:"Feature"}),(0,r.jsx)(e.th,{children:"URDF"}),(0,r.jsx)(e.th,{children:"SDF"})]})}),(0,r.jsxs)(e.tbody,{children:[(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Primary use"}),(0,r.jsx)(e.td,{children:"ROS robot description"}),(0,r.jsx)(e.td,{children:"Gazebo/Ignition simulation"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Physics parameters"}),(0,r.jsx)(e.td,{children:"Limited"}),(0,r.jsx)(e.td,{children:"Extensive"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Sensors"}),(0,r.jsx)(e.td,{children:"No native support"}),(0,r.jsx)(e.td,{children:"Full support"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Plugins"}),(0,r.jsx)(e.td,{children:"No native support"}),(0,r.jsx)(e.td,{children:"Full support"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Multi-robot worlds"}),(0,r.jsx)(e.td,{children:"No"}),(0,r.jsx)(e.td,{children:"Yes"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Materials"}),(0,r.jsx)(e.td,{children:"Basic"}),(0,r.jsx)(e.td,{children:"Advanced"})]})]})]}),"\n",(0,r.jsx)(e.h3,{id:"urdf-structure",children:"URDF Structure"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<robot name="my_robot">\r\n  <link name="base_link">\r\n    <visual>\r\n      <geometry>\r\n        <box size="1 1 1"/>\r\n      </geometry>\r\n    </visual>\r\n    <collision>\r\n      <geometry>\r\n        <box size="1 1 1"/>\r\n      </geometry>\r\n    </collision>\r\n    <inertial>\r\n      <mass value="1.0"/>\r\n      <inertia ixx="1.0" ixy="0.0" ixz="0.0" iyy="1.0" iyz="0.0" izz="1.0"/>\r\n    </inertial>\r\n  </link>\r\n\r\n  <joint name="joint1" type="revolute">\r\n    <parent link="base_link"/>\r\n    <child link="link2"/>\r\n    <axis xyz="0 0 1"/>\r\n    <limit lower="-1.57" upper="1.57" effort="100" velocity="1"/>\r\n  </joint>\r\n</robot>\n'})}),"\n",(0,r.jsx)(e.h3,{id:"sdf-structure",children:"SDF Structure"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<sdf version="1.7">\r\n  <model name="my_model">\r\n    <link name="base_link">\r\n      <visual name="visual">\r\n        <geometry>\r\n          <box>\r\n            <size>1 1 1</size>\r\n          </box>\r\n        </geometry>\r\n      </visual>\r\n      <collision name="collision">\r\n        <geometry>\r\n          <box>\r\n            <size>1 1 1</size>\r\n          </box>\r\n        </geometry>\r\n      </collision>\r\n      <inertial>\r\n        <mass>1.0</mass>\r\n        <inertia>\r\n          <ixx>1.0</ixx>\r\n          <ixy>0.0</ixy>\r\n          <ixz>0.0</ixz>\r\n          <iyy>1.0</iyy>\r\n          <iyz>0.0</iyz>\r\n          <izz>1.0</izz>\r\n        </inertia>\r\n      </inertial>\r\n    </link>\r\n\r\n    <joint name="joint1" type="revolute">\r\n      <parent>base_link</parent>\r\n      <child>link2</child>\r\n      <axis>\r\n        <xyz>0 0 1</xyz>\r\n      </axis>\r\n    </joint>\r\n  </model>\r\n</sdf>\n'})}),"\n",(0,r.jsx)(e.h3,{id:"converting-urdf-to-sdf",children:"Converting URDF to SDF"}),"\n",(0,r.jsxs)(e.p,{children:["Gazebo can automatically convert URDF to SDF, but sometimes manual intervention is needed. The conversion process uses the ",(0,r.jsx)(e.code,{children:"gz sdf"})," tool:"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"# Convert URDF to SDF\r\ngz sdf -p robot.urdf > robot.sdf\r\n\r\n# Or using the older tool\r\nign sdf -p robot.urdf > robot.sdf\n"})}),"\n",(0,r.jsx)(e.h3,{id:"adding-gazebo-specific-extensions-to-urdf",children:"Adding Gazebo-Specific Extensions to URDF"}),"\n",(0,r.jsxs)(e.p,{children:["To include Gazebo-specific elements in a URDF, use the ",(0,r.jsx)(e.code,{children:"<gazebo>"})," tags. These tags are ignored by ROS tools but processed by Gazebo."]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<robot name="my_robot_with_gazebo_extensions">\r\n  \x3c!-- Standard URDF elements --\x3e\r\n  <link name="chassis">\r\n    <visual>\r\n      <geometry>\r\n        <box size="1 0.5 0.25"/>\r\n      </geometry>\r\n    </visual>\r\n    <collision>\r\n      <geometry>\r\n        <box size="1 0.5 0.25"/>\r\n      </geometry>\r\n    </collision>\r\n    <inertial>\r\n      <mass value="5.0"/>\r\n      <inertia ixx="0.1" ixy="0" ixz="0" iyy="0.2" iyz="0" izz="0.3"/>\r\n    </inertial>\r\n  </link>\r\n\r\n  \x3c!-- Gazebo-specific extensions --\x3e\r\n  <gazebo reference="chassis">\r\n    <material>Gazebo/Blue</material>\r\n    <mu1>0.2</mu1>\r\n    <mu2>0.2</mu2>\r\n  </gazebo>\r\n</robot>\n'})}),"\n",(0,r.jsx)(e.h2,{id:"section-3-physics-simulation--sensor-simulation",children:"Section 3: Physics Simulation & Sensor Simulation"}),"\n",(0,r.jsx)(e.h3,{id:"physics-simulation-fundamentals",children:"Physics Simulation Fundamentals"}),"\n",(0,r.jsx)(e.p,{children:"Physics simulation in Gazebo is the cornerstone of effective robotics development, allowing for testing and validation of robot behaviors in a safe, cost-effective environment. For humanoid robots, accurate physics simulation is particularly important due to the complex multi-body dynamics, balance control requirements, and interaction with environments designed for humans."}),"\n",(0,r.jsx)(e.p,{children:"In Gazebo, physics simulation is handled by the Ignition Physics library, which supports multiple backend physics engines including DART, Bullet, and ODE. Each engine has its own strengths and trade-offs in terms of accuracy, stability, and computational efficiency."}),"\n",(0,r.jsx)(e.h3,{id:"core-physics-concepts",children:"Core Physics Concepts"}),"\n",(0,r.jsx)(e.h4,{id:"time-step-configuration",children:"Time Step Configuration"}),"\n",(0,r.jsx)(e.p,{children:"The time step determines how frequently the physics engine updates the simulation:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Smaller time steps"}),": More accurate simulation, higher computational cost"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Larger time steps"}),": Less accurate but faster simulation"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Recommendation for humanoid robots"}),": 0.001s to 0.005s for balance and control tasks"]}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<physics type="ode">\r\n  <max_step_size>0.001</max_step_size>\r\n  <real_time_update_rate>1000</real_time_update_rate>\r\n</physics>\n'})}),"\n",(0,r.jsx)(e.h4,{id:"real-time-factor-rtf",children:"Real Time Factor (RTF)"}),"\n",(0,r.jsx)(e.p,{children:"RTF determines how fast the simulation runs compared to real time:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"RTF = 1.0"}),": Simulation runs at real-time speed"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"RTF > 1.0"}),": Simulation runs faster than real time"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"RTF < 1.0"}),": Simulation runs slower than real time"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"solver-parameters",children:"Solver Parameters"}),"\n",(0,r.jsx)(e.p,{children:"The physics solver handles constraint resolution:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<physics type="ode">\r\n  <ode>\r\n    <solver>\r\n      <type>quick</type>  \x3c!-- or "world" --\x3e\r\n      <iters>10</iters>   \x3c!-- Number of iterations for constraint resolution --\x3e\r\n      <sor>1.3</sor>      \x3c!-- Successive Over-Relaxation parameter --\x3e\r\n    </solver>\r\n    <constraints>\r\n      <cfm>0.0</cfm>      \x3c!-- Constraint Force Mixing --\x3e\r\n      <erp>0.2</erp>      \x3c!-- Error Reduction Parameter --\x3e\r\n      <contact_max_correcting_vel>100.0</contact_max_correcting_vel>\r\n      <contact_surface_layer>0.001</contact_surface_layer>\r\n    </constraints>\r\n  </ode>\r\n</physics>\n'})}),"\n",(0,r.jsx)(e.h3,{id:"sensor-simulation-fundamentals",children:"Sensor Simulation Fundamentals"}),"\n",(0,r.jsx)(e.p,{children:"Gazebo supports several types of sensors that are essential for humanoid robotics:"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Inertial Sensors"})," (IMU, accelerometers, gyroscopes)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Vision Sensors"})," (cameras, depth cameras, stereo cameras)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Range Sensors"})," (LiDAR, sonar)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Force/Torque Sensors"})," (in joints, in feet)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Proprioceptive Sensors"})," (joint encoders, joint effort)"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"adding-noise-models",children:"Adding Noise Models"}),"\n",(0,r.jsx)(e.p,{children:"Realistic sensor noise is critical for robust algorithm development:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<sensor name="imu_sensor" type="imu">\r\n  <always_on>1</always_on>\r\n  <update_rate>100</update_rate>\r\n  <imu>\r\n    <angular_velocity>\r\n      <x>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.001</stddev>\r\n        </noise>\r\n      </x>\r\n      <y>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.001</stddev>\r\n        </noise>\r\n      </y>\r\n      <z>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.001</stddev>\r\n        </noise>\r\n      </z>\r\n    </angular_velocity>\r\n    <linear_acceleration>\r\n      <x>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.017</stddev>\r\n        </noise>\r\n      </x>\r\n      <y>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.017</stddev>\r\n        </noise>\r\n      </y>\r\n      <z>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.017</stddev>\r\n        </noise>\r\n      </z>\r\n    </linear_acceleration>\r\n  </imu>\r\n</sensor>\n'})}),"\n",(0,r.jsx)(e.h3,{id:"lidar-sensor-simulation",children:"LiDAR Sensor Simulation"}),"\n",(0,r.jsx)(e.p,{children:"LiDAR (Light Detection and Ranging) sensors are essential for humanoid robots for tasks such as mapping, localization, and obstacle detection."}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<sensor name="lidar_2d" type="ray">\r\n  <ray>\r\n    <scan>\r\n      <horizontal>\r\n        <samples>720</samples>  \x3c!-- Higher resolution for better perception --\x3e\r\n        <resolution>1</resolution>\r\n        <min_angle>-3.14159</min_angle>  \x3c!-- 180 degree FoV --\x3e\r\n        <max_angle>3.14159</max_angle>\r\n      </horizontal>\r\n    </scan>\r\n    <range>\r\n      <min>0.1</min>  \x3c!-- Minimum range --\x3e\r\n      <max>30.0</max>  \x3c!-- Maximum range --\x3e\r\n      <resolution>0.01</resolution>  \x3c!-- Resolution of sensor --\x3e\r\n    </range>\r\n  </ray>\r\n  <plugin name="lidar_2d_controller" filename="libgazebo_ros_ray_sensor.so">\r\n    <ros>\r\n      <namespace>/lidar</namespace>\r\n      <remapping>~/out:=scan</remapping>\r\n    </ros>\r\n    <output_type>sensor_msgs/LaserScan</output_type>\r\n    <frame_name>lidar_2d_frame</frame_name>\r\n  </plugin>\r\n  <always_on>true</always_on>\r\n  <update_rate>10</update_rate>  \x3c!-- Update rate in Hz --\x3e\r\n  <visualize>true</visualize>\r\n</sensor>\n'})}),"\n",(0,r.jsx)(e.h3,{id:"depth-camera-simulation",children:"Depth Camera Simulation"}),"\n",(0,r.jsx)(e.p,{children:"Depth cameras are crucial for humanoid robots for obstacle detection, manipulation planning, and 3D reconstruction."}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<sensor name="depth_camera" type="depth">\r\n  <update_rate>30</update_rate>\r\n  <camera name="head_camera">\r\n    <horizontal_fov>1.047</horizontal_fov>  \x3c!-- ~60 degrees --\x3e\r\n    <image>\r\n      <format>R8G8B8</format>  \x3c!-- Color format --\x3e\r\n      <width>640</width>\r\n      <height>480</height>\r\n    </image>\r\n    <depth_camera>\r\n      <output>depths</output>\r\n    </depth_camera>\r\n    <clip>\r\n      <near>0.1</near>   \x3c!-- Near clip plane --\x3e\r\n      <far>10.0</far>    \x3c!-- Far clip plane --\x3e\r\n    </clip>\r\n  </camera>\r\n  <plugin name="depth_camera_controller" filename="libgazebo_ros_openni_kinect.so">\r\n    <ros>\r\n      <namespace>/camera</namespace>\r\n      <remapping>rgb/image_raw:=image_color</remapping>\r\n      <remapping>depth/image_raw:=image_depth</remapping>\r\n      <remapping>depth/camera_info:=camera_info</remapping>\r\n    </ros>\r\n    <camera_name>depth_camera</camera_name>\r\n    <frame_name>camera_depth_optical_frame</frame_name>\r\n    <baseline>0.2</baseline>\r\n    <distortion_k1>0.0</distortion_k1>\r\n    <distortion_k2>0.0</distortion_k2>\r\n    <distortion_k3>0.0</distortion_k3>\r\n    <distortion_t1>0.0</distortion_t1>\r\n    <distortion_t2>0.0</distortion_t2>\r\n    <point_cloud_cutoff>0.5</point_cloud_cutoff>\r\n    <point_cloud_cutoff_max>3.0</point_cloud_cutoff_max>\r\n    <Cx_prime>0</Cx_prime>\r\n    <Cx>0.5</Cx>\r\n    <Cy>0.5</Cy>\r\n    <focal_length>0</focal_length>\r\n    <hack_baseline>0</hack_baseline>\r\n  </plugin>\r\n  <always_on>true</always_on>\r\n  <visualize>true</visualize>\r\n</sensor>\n'})}),"\n",(0,r.jsx)(e.h3,{id:"imu-simulation",children:"IMU Simulation"}),"\n",(0,r.jsx)(e.p,{children:"Inertial Measurement Units (IMUs) are critical for humanoid robots to maintain balance and determine orientation in space."}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<sensor name="imu_sensor" type="imu">\r\n  <always_on>true</always_on>\r\n  <update_rate>100</update_rate>  \x3c!-- 100Hz update rate --\x3e\r\n  <visualize>false</visualize>\r\n  <topic>imu/data</topic>\r\n\r\n  <plugin name="imu_plugin" filename="libgazebo_ros_imu_sensor.so">\r\n    <ros>\r\n      <namespace>/imu</namespace>\r\n      <remapping>~/out:=data</remapping>\r\n    </ros>\r\n    <initial_orientation_as_reference>false</initial_orientation_as_reference>\r\n    <frame_name>imu_link</frame_name>\r\n  </plugin>\r\n\r\n  <imu>\r\n    \x3c!-- Angular velocity noise --\x3e\r\n    <angular_velocity>\r\n      <x>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.0017</stddev>  \x3c!-- ~0.1 deg/s (ADIS16448 spec) --\x3e\r\n          <bias_mean>0.0</bias_mean>\r\n          <bias_stddev>0.0012</bias_stddev>  \x3c!-- ~0.07 deg/s bias drift --\x3e\r\n        </noise>\r\n      </x>\r\n      <y>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.0017</stddev>\r\n          <bias_mean>0.0</bias_mean>\r\n          <bias_stddev>0.0012</bias_stddev>\r\n        </noise>\r\n      </y>\r\n      <z>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.0017</stddev>\r\n          <bias_mean>0.0</bias_mean>\r\n          <bias_stddev>0.0012</bias_stddev>\r\n        </noise>\r\n      </z>\r\n    </angular_velocity>\r\n\r\n    \x3c!-- Linear acceleration noise --\x3e\r\n    <linear_acceleration>\r\n      <x>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.017</stddev>  \x3c!-- ~0.0017g (ADIS16448 spec) --\x3e\r\n          <bias_mean>0.0</bias_mean>\r\n          <bias_stddev>0.0098</bias_stddev>  \x3c!-- ~0.001g bias drift --\x3e\r\n        </noise>\r\n      </x>\r\n      <y>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.017</stddev>\r\n          <bias_mean>0.0</bias_mean>\r\n          <bias_stddev>0.0098</bias_stddev>\r\n        </noise>\r\n      </y>\r\n      <z>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.017</stddev>\r\n          <bias_mean>0.0</bias_mean>\r\n          <bias_stddev>0.0098</bias_stddev>\r\n        </noise>\r\n      </z>\r\n    </linear_acceleration>\r\n  </imu>\r\n</sensor>\n'})}),"\n",(0,r.jsx)(e.h2,{id:"section-4-gazebo-physics-collisions-environment-design",children:"Section 4: Gazebo Physics, Collisions, Environment Design"}),"\n",(0,r.jsx)(e.h3,{id:"physics-simulation-fundamentals-1",children:"Physics Simulation Fundamentals"}),"\n",(0,r.jsx)(e.p,{children:"Physics simulation in Gazebo is the cornerstone of effective robotics development, allowing for testing and validation of robot behaviors in a safe, cost-effective environment. For humanoid robots, accurate physics simulation is particularly important due to the complex multi-body dynamics, balance control requirements, and interaction with environments designed for humans."}),"\n",(0,r.jsx)(e.p,{children:"In Gazebo, physics simulation is handled by the Ignition Physics library, which supports multiple backend physics engines including DART, Bullet, and ODE. Each engine has its own strengths and trade-offs in terms of accuracy, stability, and computational efficiency."}),"\n",(0,r.jsx)(e.h3,{id:"core-physics-concepts-1",children:"Core Physics Concepts"}),"\n",(0,r.jsx)(e.h4,{id:"time-step-configuration-1",children:"Time Step Configuration"}),"\n",(0,r.jsx)(e.p,{children:"The time step determines how frequently the physics engine updates the simulation:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Smaller time steps"}),": More accurate simulation, higher computational cost"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Larger time steps"}),": Less accurate but faster simulation"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Recommendation for humanoid robots"}),": 0.001s to 0.005s for balance and control tasks"]}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<physics type="ode">\r\n  <max_step_size>0.001</max_step_size>\r\n  <real_time_update_rate>1000</real_time_update_rate>\r\n</physics>\n'})}),"\n",(0,r.jsx)(e.h4,{id:"real-time-factor-rtf-1",children:"Real Time Factor (RTF)"}),"\n",(0,r.jsx)(e.p,{children:"RTF determines how fast the simulation runs compared to real time:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"RTF = 1.0"}),": Simulation runs at real-time speed"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"RTF > 1.0"}),": Simulation runs faster than real time"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"RTF < 1.0"}),": Simulation runs slower than real time"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"solver-parameters-1",children:"Solver Parameters"}),"\n",(0,r.jsx)(e.p,{children:"The physics solver handles constraint resolution:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<physics type="ode">\r\n  <ode>\r\n    <solver>\r\n      <type>quick</type>  \x3c!-- or "world" --\x3e\r\n      <iters>10</iters>   \x3c!-- Number of iterations for constraint resolution --\x3e\r\n      <sor>1.3</sor>      \x3c!-- Successive Over-Relaxation parameter --\x3e\r\n    </solver>\r\n    <constraints>\r\n      <cfm>0.0</cfm>      \x3c!-- Constraint Force Mixing --\x3e\r\n      <erp>0.2</erp>      \x3c!-- Error Reduction Parameter --\x3e\r\n      <contact_max_correcting_vel>100.0</contact_max_correcting_vel>\r\n      <contact_surface_layer>0.001</contact_surface_layer>\r\n    </constraints>\r\n  </ode>\r\n</physics>\n'})}),"\n",(0,r.jsx)(e.h3,{id:"collision-modeling-for-humanoids",children:"Collision Modeling for Humanoids"}),"\n",(0,r.jsx)(e.h4,{id:"collision-geometry-selection",children:"Collision Geometry Selection"}),"\n",(0,r.jsx)(e.p,{children:"Choosing appropriate collision geometries is crucial for humanoid simulation:"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Primitive Shapes"}),": Boxes, spheres, and cylinders for basic collision detection"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Convex Hulls"}),": For more accurate approximations of complex shapes"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Triangle Meshes"}),": For detailed collision in critical areas"]}),"\n"]}),"\n",(0,r.jsx)(e.h4,{id:"multi-collision-links",children:"Multi-Collision Links"}),"\n",(0,r.jsx)(e.p,{children:"For better simulation accuracy, use multiple collision elements per link:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<link name="upper_arm">\r\n  <collision name="upper_arm_collision_main">\r\n    <geometry>\r\n      <capsule>\r\n        <radius>0.05</radius>\r\n        <length>0.2</length>\r\n      </capsule>\r\n    </geometry>\r\n  </collision>\r\n\r\n  <collision name="upper_arm_collision_elbow">\r\n    <pose>0.0 0.0 -0.1 0 0 0</pose>\r\n    <geometry>\r\n      <sphere>\r\n        <radius>0.06</radius>\r\n      </sphere>\r\n    </geometry>\r\n  </collision>\r\n</link>\n'})}),"\n",(0,r.jsx)(e.h4,{id:"contact-stabilization",children:"Contact Stabilization"}),"\n",(0,r.jsx)(e.p,{children:"Stabilizing contacts is essential for humanoid balance:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<collision name="foot_collision">\r\n  <surface>\r\n    <contact>\r\n      <ode>\r\n        <max_vel>100.0</max_vel>\r\n        <min_depth>0.001</min_depth>\r\n        <soft_cfm>0.001</soft_cfm>\r\n        <soft_erp>0.99</soft_erp>\r\n      </ode>\r\n    </contact>\r\n    <friction>\r\n      <ode>\r\n        <mu>0.8</mu>\r\n        <mu2>0.8</mu2>\r\n        <fdir1>0 0 0</fdir1>\r\n        <slip1>0.0</slip1>\r\n        <slip2>0.0</slip2>\r\n      </ode>\r\n    </friction>\r\n  </surface>\r\n</collision>\n'})}),"\n",(0,r.jsx)(e.h3,{id:"environment-design-for-humanoid-robots",children:"Environment Design for Humanoid Robots"}),"\n",(0,r.jsx)(e.h4,{id:"creating-human-scale-environments",children:"Creating Human-Scale Environments"}),"\n",(0,r.jsx)(e.p,{children:"Humanoid robots need environments designed for human dimensions:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<sdf version="1.7">\r\n  <world name="humanoid_environment">\r\n    \x3c!-- Physics --\x3e\r\n    <physics type="dart">\r\n      <max_step_size>0.001</max_step_size>\r\n      <real_time_update_rate>1000</real_time_update_rate>\r\n    </physics>\r\n\r\n    \x3c!-- Main floor --\x3e\r\n    <model name="floor">\r\n      <static>true</static>\r\n      <link name="floor_link">\r\n        <collision name="floor_collision">\r\n          <geometry>\r\n            <plane>\r\n              <normal>0 0 1</normal>\r\n              <size>10 10</size>\r\n            </plane>\r\n          </geometry>\r\n        </collision>\r\n        <visual name="floor_visual">\r\n          <geometry>\r\n            <plane>\r\n              <normal>0 0 1</normal>\r\n              <size>10 10</size>\r\n            </plane>\r\n          </geometry>\r\n          <material>\r\n            <ambient>0.7 0.7 0.7 1</ambient>\r\n            <diffuse>0.8 0.8 0.8 1</diffuse>\r\n            <specular>0.1 0.1 0.1 1</specular>\r\n          </material>\r\n        </visual>\r\n      </link>\r\n    </model>\r\n\r\n    \x3c!-- Doorway for navigation --\x3e\r\n    <model name="doorway">\r\n      <pose>0 0 0 0 0 0</pose>\r\n      <link name="doorway_frame">\r\n        <collision name="left_jamb">\r\n          <geometry>\r\n            <box>\r\n              <size>0.2 0.1 2.0</size>\r\n            </box>\r\n          </geometry>\r\n        </collision>\r\n        <visual name="left_jamb_visual">\r\n          <geometry>\r\n            <box>\r\n              <size>0.2 0.1 2.0</size>\r\n            </box>\r\n          </geometry>\r\n        </visual>\r\n      </link>\r\n\r\n      <link name="doorway_top">\r\n        <pose>0 0.6 1.0 0 0 0</pose>\r\n        <collision name="top_jamb">\r\n          <geometry>\r\n            <box>\r\n              <size>0.2 1.2 0.2</size>\r\n            </box>\r\n          </geometry>\r\n        </collision>\r\n        <visual name="top_jamb_visual">\r\n          <geometry>\r\n            <box>\r\n              <size>0.2 1.2 0.2</size>\r\n            </box>\r\n          </geometry>\r\n        </visual>\r\n      </link>\r\n    </model>\r\n  </world>\r\n</sdf>\n'})}),"\n",(0,r.jsx)(e.h4,{id:"furniture-and-obstacles",children:"Furniture and Obstacles"}),"\n",(0,r.jsx)(e.p,{children:"Humanoid robots interact with furniture designed for humans:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<sdf version="1.7">\r\n  <model name="chair">\r\n    <link name="seat">\r\n      <pose>0 0 0.45 0 0 0</pose>\r\n      <collision>\r\n        <geometry>\r\n          <box>\r\n            <size>0.4 0.4 0.02</size>\r\n          </box>\r\n        </geometry>\r\n      </collision>\r\n      <visual>\r\n        <geometry>\r\n          <box>\r\n            <size>0.4 0.4 0.02</size>\r\n        </geometry>\r\n      </visual>\r\n    </link>\r\n\r\n    <link name="back_rest">\r\n      <pose>0 -0.15 0.7 0 0 0</pose>\r\n      <collision>\r\n        <geometry>\r\n          <box>\r\n            <size>0.4 0.02 0.4</size>\r\n          </box>\r\n        </geometry>\r\n      </collision>\r\n      <visual>\r\n        <geometry>\r\n          <box>\r\n            <size>0.4 0.02 0.4</size>\r\n          </geometry>\r\n      </visual>\r\n    </link>\r\n\r\n    <link name="leg_front_left">\r\n      <pose>-0.15 -0.15 0.23 0 0 0</pose>\r\n      <collision>\r\n        <geometry>\r\n          <cylinder>\r\n            <radius>0.02</radius>\r\n            <length>0.46</length>\r\n          </cylinder>\r\n        </geometry>\r\n      </collision>\r\n    </link>\r\n\r\n    \x3c!-- Additional legs... --\x3e\r\n  </model>\r\n</sdf>\n'})}),"\n",(0,r.jsx)(e.h2,{id:"section-5-sensor-simulation-lidar-depth-imu",children:"Section 5: Sensor Simulation (LiDAR, Depth, IMU)"}),"\n",(0,r.jsx)(e.h3,{id:"sensor-simulation-fundamentals-1",children:"Sensor Simulation Fundamentals"}),"\n",(0,r.jsx)(e.p,{children:"Gazebo supports several types of sensors that are essential for humanoid robotics:"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Inertial Sensors"})," (IMU, accelerometers, gyroscopes)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Vision Sensors"})," (cameras, depth cameras, stereo cameras)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Range Sensors"})," (LiDAR, sonar)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Force/Torque Sensors"})," (in joints, in feet)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Proprioceptive Sensors"})," (joint encoders, joint effort)"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"adding-noise-models-1",children:"Adding Noise Models"}),"\n",(0,r.jsx)(e.p,{children:"Realistic sensor noise is critical for robust algorithm development:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<sensor name="imu_sensor" type="imu">\r\n  <always_on>1</always_on>\r\n  <update_rate>100</update_rate>\r\n  <imu>\r\n    <angular_velocity>\r\n      <x>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.001</stddev>\r\n        </noise>\r\n      </x>\r\n      <y>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.001</stddev>\r\n        </noise>\r\n      </y>\r\n      <z>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.001</stddev>\r\n        </noise>\r\n      </z>\r\n    </angular_velocity>\r\n    <linear_acceleration>\r\n      <x>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.017</stddev>\r\n        </noise>\r\n      </x>\r\n      <y>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.017</stddev>\r\n        </noise>\r\n      </y>\r\n      <z>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.017</stddev>\r\n        </noise>\r\n      </z>\r\n    </linear_acceleration>\r\n  </imu>\r\n</sensor>\n'})}),"\n",(0,r.jsx)(e.h3,{id:"lidar-simulation-in-detail",children:"LiDAR Simulation in Detail"}),"\n",(0,r.jsx)(e.p,{children:"LiDAR sensors are critical for humanoid navigation and mapping. For humanoid robots, we typically use 2D LiDAR sensors mounted on the robot to detect obstacles and map the environment:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<sensor name="front_lidar" type="ray">\r\n  <pose>0.2 0 0.5 0 0 0</pose>  \x3c!-- Mount the LiDAR on the front of the robot --\x3e\r\n  <ray>\r\n    <scan>\r\n      <horizontal>\r\n        <samples>360</samples>  \x3c!-- 360 samples = 1 degree resolution --\x3e\r\n        <resolution>1</resolution>\r\n        <min_angle>-3.14159</min_angle>  \x3c!-- Full 360 degree scan --\x3e\r\n        <max_angle>3.14159</max_angle>\r\n      </horizontal>\r\n    </scan>\r\n    <range>\r\n      <min>0.1</min>\r\n      <max>10.0</max>  \x3c!-- 10 meter range is sufficient for humanoid navigation --\x3e\r\n      <resolution>0.01</resolution>\r\n    </range>\r\n  </ray>\r\n  <plugin name="front_lidar_controller" filename="libgazebo_ros_ray_sensor.so">\r\n    <ros>\r\n      <namespace>/lidar</namespace>\r\n      <remapping>~/out:=scan</remapping>\r\n    </ros>\r\n    <output_type>sensor_msgs/LaserScan</output_type>\r\n    <frame_name>front_lidar_frame</frame_name>\r\n  </plugin>\r\n  <always_on>true</always_on>\r\n  <update_rate>10</update_rate>\r\n  <visualize>false</visualize>\r\n</sensor>\n'})}),"\n",(0,r.jsx)(e.h3,{id:"depth-camera-simulation-for-3d-perception",children:"Depth Camera Simulation for 3D Perception"}),"\n",(0,r.jsx)(e.p,{children:"For humanoid robots, depth cameras provide crucial 3D perception capabilities:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<sensor name="head_camera" type="depth">\r\n  <pose>0 0 0.8 0 0 0</pose>  \x3c!-- Mount on robot head --\x3e\r\n  <camera name="head_camera">\r\n    <horizontal_fov>1.047</horizontal_fov>  \x3c!-- 60 degrees --\x3e\r\n    <image>\r\n      <format>R8G8B8</format>\r\n      <width>640</width>\r\n      <height>480</height>\r\n    </image>\r\n    <clip>\r\n      <near>0.1</near>\r\n      <far>10</far>\r\n    </clip>\r\n  </camera>\r\n  <plugin name="head_camera_controller" filename="libgazebo_ros_openni_kinect.so">\r\n    <ros>\r\n      <namespace>/camera</namespace>\r\n    </ros>\r\n    <frame_name>camera_depth_optical_frame</frame_name>\r\n  </plugin>\r\n  <always_on>true</always_on>\r\n  <update_rate>30</update_rate>\r\n  <visualize>true</visualize>\r\n</sensor>\n'})}),"\n",(0,r.jsx)(e.h3,{id:"imu-simulation-for-humanoid-balance",children:"IMU Simulation for Humanoid Balance"}),"\n",(0,r.jsx)(e.p,{children:"IMU sensors are critical for humanoid balance and orientation estimation:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-xml",children:'<sensor name="torso_imu" type="imu">\r\n  <pose>0 0 0.5 0 0 0</pose>  \x3c!-- Mount near robot\'s center of mass --\x3e\r\n  <plugin name="imu_controller" filename="libgazebo_ros_imu.so">\r\n    <ros>\r\n      <namespace>/imu</namespace>\r\n    </ros>\r\n    <frame_name>imu_link</frame_name>\r\n  </plugin>\r\n  <always_on>true</always_on>\r\n  <update_rate>100</update_rate>\r\n  <imu>\r\n    <angular_velocity>\r\n      <x>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.0003</stddev>\r\n          <bias_mean>0.0000075</bias_mean>\r\n          <bias_stddev>0.0000008</bias_stddev>\r\n        </noise>\r\n      </x>\r\n      <y>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.0003</stddev>\r\n          <bias_mean>0.0000075</bias_mean>\r\n          <bias_stddev>0.0000008</bias_stddev>\r\n        </noise>\r\n      </y>\r\n      <z>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.0003</stddev>\r\n          <bias_mean>0.0000075</bias_mean>\r\n          <bias_stddev>0.0000008</bias_stddev>\r\n        </noise>\r\n      </z>\r\n    </angular_velocity>\r\n    <linear_acceleration>\r\n      <x>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.017</stddev>\r\n          <bias_mean>0.1</bias_mean>\r\n          <bias_stddev>0.001</bias_stddev>\r\n        </noise>\r\n      </x>\r\n      <y>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.017</stddev>\r\n          <bias_mean>0.1</bias_mean>\r\n          <bias_stddev>0.001</bias_stddev>\r\n        </noise>\r\n      </y>\r\n      <z>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.017</stddev>\r\n          <bias_mean>0.1</bias_mean>\r\n          <bias_stddev>0.001</bias_stddev>\r\n        </noise>\r\n      </z>\r\n    </linear_acceleration>\r\n  </imu>\r\n</sensor>\n'})}),"\n",(0,r.jsx)(e.h2,{id:"section-6-unity-integration-for-robot-visualization",children:"Section 6: Unity Integration for Robot Visualization"}),"\n",(0,r.jsx)(e.p,{children:"While Gazebo provides excellent physics simulation capabilities, Unity offers advanced visualization and rendering capabilities that can complement robotics development. Unity can be integrated with ROS 2 through the Unity Robotics Package."}),"\n",(0,r.jsx)(e.h3,{id:"setting-up-unity-for-robotics",children:"Setting Up Unity for Robotics"}),"\n",(0,r.jsx)(e.p,{children:"Unity can be used for:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"High-quality visualization of robot models"}),"\n",(0,r.jsx)(e.li,{children:"VR/AR interfaces for robot teleoperation"}),"\n",(0,r.jsx)(e.li,{children:"Creating training environments for machine learning"}),"\n",(0,r.jsx)(e.li,{children:"Developing user interfaces for robot monitoring"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"basic-unity-ros-2-integration",children:"Basic Unity-ROS 2 Integration"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\r\nusing Unity.Robotics.ROSTCPConnector;\r\nusing RosMessageTypes.Sensor;\r\n\r\npublic class IMUReceiver : MonoBehaviour\r\n{\r\n    private ROSConnection ros;\r\n    private ImuMsg imuData;\r\n\r\n    // Start is called before the first frame update\r\n    void Start()\r\n    {\r\n        ros = ROSConnection.GetOrCreateInstance();\r\n        ros.Subscribe<ImuMsg>("/imu/data", IMUCallback);\r\n    }\r\n\r\n    void IMUCallback(ImuMsg msg)\r\n    {\r\n        this.imuData = msg;\r\n        \r\n        // Update robot orientation based on IMU data\r\n        transform.rotation = new Quaternion(\r\n            (float)msg.orientation.x,\r\n            (float)msg.orientation.y,\r\n            (float)msg.orientation.z,\r\n            (float)msg.orientation.w\r\n        );\r\n    }\r\n}\n'})}),"\n",(0,r.jsx)(e.h3,{id:"unity-for-robot-visualization",children:"Unity for Robot Visualization"}),"\n",(0,r.jsx)(e.p,{children:"Unity's rendering capabilities make it ideal for:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Creating photorealistic simulation environments"}),"\n",(0,r.jsx)(e.li,{children:"Developing intuitive user interfaces"}),"\n",(0,r.jsx)(e.li,{children:"Visualizing complex sensor data"}),"\n",(0,r.jsx)(e.li,{children:"Creating training environments for deep learning"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"section-7-simulation-best-practices",children:"Section 7: Simulation Best Practices"}),"\n",(0,r.jsx)(e.h3,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,r.jsx)(e.p,{children:"When running complex humanoid robot simulations, performance becomes a critical concern:"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Reducing visual complexity"}),": Use simpler visual meshes than collision meshes"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Optimizing physics parameters"}),": Balance accuracy with performance"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Limiting update rates"}),": Use appropriate update rates for different sensors"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Using simpler collision shapes"}),": Approximate complex geometries with primitives"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"debugging-techniques",children:"Debugging Techniques"}),"\n",(0,r.jsx)(e.p,{children:"Effective debugging in simulation includes:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Visualizing sensor data in real-time"}),"\n",(0,r.jsx)(e.li,{children:"Recording and replaying simulation sessions"}),"\n",(0,r.jsx)(e.li,{children:"Checking for joint limits and collisions"}),"\n",(0,r.jsx)(e.li,{children:"Monitoring robot states through ROS 2 tools"}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"# Monitor robot states\r\nros2 topic echo /joint_states\r\n\r\n# Visualize with RViz2\r\nrviz2\r\n\r\n# Check TF frames\r\nros2 run tf2_tools view_frames\n"})}),"\n",(0,r.jsx)(e.h3,{id:"validation-techniques",children:"Validation Techniques"}),"\n",(0,r.jsx)(e.p,{children:"To ensure simulation accuracy:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Compare simulation results with real robot behavior"}),"\n",(0,r.jsx)(e.li,{children:"Use simulation parameters based on real robot specifications"}),"\n",(0,r.jsx)(e.li,{children:"Validate physics parameters against real-world measurements"}),"\n",(0,r.jsx)(e.li,{children:"Implement hardware-in-the-loop testing when possible"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"exercises",children:"Exercises"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Setup Gazebo"}),": Install Gazebo Garden with ROS 2 Humble packages and verify the installation by launching the simulator."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Create a Simple Robot Model"}),": Design a simple humanoid robot model in URDF with at least 6 degrees of freedom and convert it to SDF."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Physics Configuration"}),": Configure physics parameters for a humanoid robot with appropriate time steps and solver parameters for stable walking simulation."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Sensor Integration"}),": Add LiDAR, IMU, and depth camera sensors to your robot model with realistic noise models."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Environment Design"}),": Create a simple indoor environment with furniture appropriate for humanoid navigation."]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Simulation Scenario"}),": Design a simulation scenario where the humanoid robot navigates through an obstacle course and collects sensor data."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"quiz",children:"Quiz"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"What is the recommended time step for humanoid robot simulation in Gazebo for balance control?"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"A) 0.1 seconds"}),"\n",(0,r.jsx)(e.li,{children:"B) 0.01 seconds"}),"\n",(0,r.jsx)(e.li,{children:"C) 0.001 seconds"}),"\n",(0,r.jsx)(e.li,{children:"D) 0.0001 seconds"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Which physics engine is particularly well-suited for articulated systems like humanoid robots?"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"A) ODE"}),"\n",(0,r.jsx)(e.li,{children:"B) Bullet"}),"\n",(0,r.jsx)(e.li,{children:"C) DART"}),"\n",(0,r.jsx)(e.li,{children:"D) PhysX"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"What does SDF stand for in the context of Gazebo?"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"A) Simulation Description Format"}),"\n",(0,r.jsx)(e.li,{children:"B) Standard Development Framework"}),"\n",(0,r.jsx)(e.li,{children:"C) System Definition File"}),"\n",(0,r.jsx)(e.li,{children:"D) Sensor Data Format"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"What is the main advantage of using URDF in ROS-based robotics projects?"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"A) Better physics simulation"}),"\n",(0,r.jsx)(e.li,{children:"B) Tight integration with ROS tools and ecosystem"}),"\n",(0,r.jsx)(e.li,{children:"C) More complex sensor modeling"}),"\n",(0,r.jsx)(e.li,{children:"D) Better visualization capabilities"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"Which of these is NOT a typical sensor simulated in Gazebo for humanoid robots?"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"A) LiDAR"}),"\n",(0,r.jsx)(e.li,{children:"B) IMU"}),"\n",(0,r.jsx)(e.li,{children:"C) GPS"}),"\n",(0,r.jsx)(e.li,{children:"D) Odometer"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"reflection",children:"Reflection"}),"\n",(0,r.jsx)(e.p,{children:"Consider how simulation can accelerate robot development while acknowledging its limitations. What are the main differences between simulated and real robots that might affect the performance of your control algorithms? How would you design your simulation environment to be as realistic as possible while maintaining computational efficiency? What validation methods would you use to ensure that behaviors that work in simulation will transfer successfully to real hardware?"})]})}function m(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(d,{...n})}):d(n)}}}]);