"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[1302],{4630:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>o,contentTitle:()=>s,default:()=>p,frontMatter:()=>r,metadata:()=>l,toc:()=>c});var t=i(4848),a=i(8453);const r={title:"Cognitive Planning & Actions",description:"Understanding cognitive planning in robotics and how intelligent agents select and execute actions",tags:["Cognitive Robotics","Planning","AI Actions","Robot Decision Making","Task Planning"]},s="Cognitive Planning & Actions",l={id:"week-8-10/cognitive-planning-actions",title:"Cognitive Planning & Actions",description:"Understanding cognitive planning in robotics and how intelligent agents select and execute actions",source:"@site/docs/week-8-10/cognitive-planning-actions.md",sourceDirName:"week-8-10",slug:"/week-8-10/cognitive-planning-actions",permalink:"/New-Physical-AI-and-Humanoid-Robotics/docs/week-8-10/cognitive-planning-actions",draft:!1,unlisted:!1,editUrl:"https://github.com/JaveriaNigar/New-Physical-AI-and-Humanoid-Robotics/docs/week-8-10/cognitive-planning-actions.md",tags:[{label:"Cognitive Robotics",permalink:"/New-Physical-AI-and-Humanoid-Robotics/docs/tags/cognitive-robotics"},{label:"Planning",permalink:"/New-Physical-AI-and-Humanoid-Robotics/docs/tags/planning"},{label:"AI Actions",permalink:"/New-Physical-AI-and-Humanoid-Robotics/docs/tags/ai-actions"},{label:"Robot Decision Making",permalink:"/New-Physical-AI-and-Humanoid-Robotics/docs/tags/robot-decision-making"},{label:"Task Planning",permalink:"/New-Physical-AI-and-Humanoid-Robotics/docs/tags/task-planning"}],version:"current",frontMatter:{title:"Cognitive Planning & Actions",description:"Understanding cognitive planning in robotics and how intelligent agents select and execute actions",tags:["Cognitive Robotics","Planning","AI Actions","Robot Decision Making","Task Planning"]},sidebar:"tutorialSidebar",previous:{title:"NVIDIA Isaac Architecture",permalink:"/New-Physical-AI-and-Humanoid-Robotics/docs/week-8-10/nvidia-isaac-architecture"},next:{title:"Humanoid Development Overview",permalink:"/New-Physical-AI-and-Humanoid-Robotics/docs/week-11-13/humanoid-development-overview"}},o={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction to Cognitive Planning",id:"introduction-to-cognitive-planning",level:2},{value:"Planning Paradigms",id:"planning-paradigms",level:2},{value:"Hierarchical Task Networks (HTN)",id:"hierarchical-task-networks-htn",level:3},{value:"Classical Planning (STRIPS)",id:"classical-planning-strips",level:3},{value:"Partial Order Planning",id:"partial-order-planning",level:3},{value:"Action Representation and Selection",id:"action-representation-and-selection",level:2},{value:"Action Models",id:"action-models",level:3},{value:"Action Selection Mechanisms",id:"action-selection-mechanisms",level:3},{value:"Utility-Based Selection",id:"utility-based-selection",level:4},{value:"Goal-Directed Selection",id:"goal-directed-selection",level:4},{value:"Planning Algorithms",id:"planning-algorithms",level:2},{value:"Forward Search (Progression Planning)",id:"forward-search-progression-planning",level:3},{value:"Backward Search (Regression Planning)",id:"backward-search-regression-planning",level:3},{value:"Graphplan",id:"graphplan",level:3},{value:"Reactive Planning",id:"reactive-planning",level:2},{value:"Deliberative vs. Reactive Systems",id:"deliberative-vs-reactive-systems",level:3},{value:"Multi-Level Planning",id:"multi-level-planning",level:2},{value:"Integration of Different Planning Levels",id:"integration-of-different-planning-levels",level:3},{value:"Planning under Uncertainty",id:"planning-under-uncertainty",level:2},{value:"Probabilistic Planning",id:"probabilistic-planning",level:3},{value:"Contingent Planning",id:"contingent-planning",level:3},{value:"Planning in Dynamic Environments",id:"planning-in-dynamic-environments",level:2},{value:"Replanning Strategies",id:"replanning-strategies",level:3},{value:"Cognitive Architecture Integration",id:"cognitive-architecture-integration",level:2},{value:"Planning in Cognitive Architectures",id:"planning-in-cognitive-architectures",level:3},{value:"Performance Considerations",id:"performance-considerations",level:2},{value:"Planning Efficiency",id:"planning-efficiency",level:3},{value:"Heuristic Functions",id:"heuristic-functions",level:4},{value:"Plan Repair",id:"plan-repair",level:4},{value:"Real-World Applications",id:"real-world-applications",level:2},{value:"Service Robotics",id:"service-robotics",level:3},{value:"Manufacturing Robotics",id:"manufacturing-robotics",level:3},{value:"Challenges and Future Directions",id:"challenges-and-future-directions",level:2},{value:"Scalability Challenges",id:"scalability-challenges",level:3},{value:"State Space Explosion",id:"state-space-explosion",level:4},{value:"Real-Time Requirements",id:"real-time-requirements",level:4},{value:"Integration Challenges",id:"integration-challenges",level:3},{value:"Perception-Action Loops",id:"perception-action-loops",level:4},{value:"Human-Robot Interaction",id:"human-robot-interaction",level:4},{value:"Exercises",id:"exercises",level:2},{value:"Quiz",id:"quiz",level:2},{value:"Reflection",id:"reflection",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.h1,{id:"cognitive-planning--actions",children:"Cognitive Planning & Actions"}),"\n",(0,t.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(e.p,{children:"By the end of this chapter, students will be able to:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Explain the principles of cognitive planning in robotics"}),"\n",(0,t.jsx)(e.li,{children:"Implement task planning algorithms for robotic systems"}),"\n",(0,t.jsx)(e.li,{children:"Design action selection mechanisms for intelligent agents"}),"\n",(0,t.jsx)(e.li,{children:"Analyze the relationship between perception, planning, and action execution"}),"\n",(0,t.jsx)(e.li,{children:"Evaluate the efficiency and effectiveness of planning algorithms"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"introduction-to-cognitive-planning",children:"Introduction to Cognitive Planning"}),"\n",(0,t.jsx)(e.p,{children:"Cognitive planning in robotics refers to the process by which intelligent robots decide what actions to perform to achieve their goals. Unlike reactive systems that respond directly to stimuli, cognitive systems use internal reasoning to determine their behavior. This involves understanding the current state of the world, predicting the outcomes of possible actions, and selecting actions that move the system toward its goals."}),"\n",(0,t.jsx)(e.p,{children:"Cognitive planning encompasses multiple levels of abstraction:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Task planning"}),": High-level goal decomposition"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Motion planning"}),": Pathfinding and trajectory generation"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Action planning"}),": Sequencing of primitive actions"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Reactive planning"}),": Immediate response to unexpected events"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"planning-paradigms",children:"Planning Paradigms"}),"\n",(0,t.jsx)(e.h3,{id:"hierarchical-task-networks-htn",children:"Hierarchical Task Networks (HTN)"}),"\n",(0,t.jsx)(e.p,{children:"Hierarchical Task Networks decompose complex tasks into simpler subtasks in a hierarchical structure:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"class HTNPlanner:\r\n    def __init__(self):\r\n        self.primitive_actions = {\r\n            'move_to': self.move_to,\r\n            'pick_up': self.pick_up,\r\n            'place_down': self.place_down\r\n        }\r\n        \r\n        self.complex_tasks = {\r\n            'assemble_product': [\r\n                ('move_to', 'part_a_location'),\r\n                ('pick_up', 'part_a'),\r\n                ('move_to', 'assembly_station'),\r\n                ('place_down', 'part_a'),\r\n                ('move_to', 'part_b_location'),\r\n                ('pick_up', 'part_b'),\r\n                ('move_to', 'assembly_station'),\r\n                ('place_down', 'part_b'),\r\n                ('perform_assembly', 'part_a', 'part_b')\r\n            ]\r\n        }\r\n    \r\n    def plan(self, task, state):\r\n        if task in self.primitive_actions:\r\n            return [task]\r\n        elif task in self.complex_tasks:\r\n            plan = []\r\n            for subtask in self.complex_tasks[task]:\r\n                subplan = self.plan(subtask[0], state)\r\n                plan.extend(subplan)\r\n                # Update state after each subtask\r\n                state = self.execute_and_update_state(subtask, state)\r\n            return plan\r\n    \r\n    def execute_and_update_state(self, action, state):\r\n        # Execute action and return updated state\r\n        return state\n"})}),"\n",(0,t.jsx)(e.h3,{id:"classical-planning-strips",children:"Classical Planning (STRIPS)"}),"\n",(0,t.jsx)(e.p,{children:"Classical planning uses formal logic to represent states, actions, and goals:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"class STRIPSAction:\r\n    def __init__(self, name, preconditions, effects):\r\n        self.name = name\r\n        self.preconditions = preconditions  # Set of facts that must be true\r\n        self.effects = effects  # Set of facts that become true/removed\r\n\r\nclass STRIPSPlanner:\r\n    def __init__(self, actions, initial_state, goal_state):\r\n        self.actions = actions\r\n        self.initial_state = initial_state\r\n        self.goal_state = goal_state\r\n    \r\n    def plan(self):\r\n        # Use algorithms like A* or Forward Search\r\n        return self.forward_search(self.initial_state, self.goal_state)\r\n    \r\n    def forward_search(self, start_state, goal_state):\r\n        # Implementation of forward search algorithm\r\n        pass\n"})}),"\n",(0,t.jsx)(e.h3,{id:"partial-order-planning",children:"Partial Order Planning"}),"\n",(0,t.jsx)(e.p,{children:"Partial order planning maintains flexibility by not ordering actions that don't need to be ordered:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"class PartialOrderPlan:\r\n    def __init__(self):\r\n        self.steps = []\r\n        self.ordering_constraints = []  # List of (before, after) tuples\r\n        self.causal_links = []  # List of (step, condition, step)\r\n    \r\n    def add_step(self, action):\r\n        self.steps.append(action)\r\n    \r\n    def add_ordering(self, before, after):\r\n        self.ordering_constraints.append((before, after))\r\n    \r\n    def add_causal_link(self, producer, condition, consumer):\r\n        self.causal_links.append((producer, condition, consumer))\n"})}),"\n",(0,t.jsx)(e.h2,{id:"action-representation-and-selection",children:"Action Representation and Selection"}),"\n",(0,t.jsx)(e.h3,{id:"action-models",children:"Action Models"}),"\n",(0,t.jsx)(e.p,{children:"Actions in cognitive robotics are typically represented with:"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Preconditions"}),": Conditions that must be true for the action to be executed"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Effects"}),": Changes to the world state when the action is executed"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Costs"}),": Resource consumption or time required"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Qualifications"}),": Context-dependent constraints"]}),"\n"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'class Action:\r\n    def __init__(self, name, preconditions, add_effects, del_effects, cost=1):\r\n        self.name = name\r\n        self.preconditions = set(preconditions)\r\n        self.add_effects = set(add_effects)  # Facts that become true\r\n        self.del_effects = set(del_effects)  # Facts that become false\r\n        self.cost = cost\r\n    \r\n    def applicable(self, state):\r\n        return self.preconditions.issubset(state)\r\n    \r\n    def apply(self, state):\r\n        if not self.applicable(state):\r\n            raise ValueError("Action not applicable in current state")\r\n        \r\n        new_state = state.copy()\r\n        new_state.update(self.add_effects)\r\n        new_state.difference_update(self.del_effects)\r\n        return new_state\n'})}),"\n",(0,t.jsx)(e.h3,{id:"action-selection-mechanisms",children:"Action Selection Mechanisms"}),"\n",(0,t.jsx)(e.h4,{id:"utility-based-selection",children:"Utility-Based Selection"}),"\n",(0,t.jsx)(e.p,{children:"Actions are selected based on their expected utility:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"class UtilityBasedPlanner:\r\n    def __init__(self, actions, utility_function):\r\n        self.actions = actions\r\n        self.utility_function = utility_function\r\n    \r\n    def select_action(self, state, goals):\r\n        best_action = None\r\n        best_utility = float('-inf')\r\n        \r\n        for action in self.actions:\r\n            if action.applicable(state):\r\n                resulting_state = action.apply(state)\r\n                utility = self.utility_function(resulting_state, goals)\r\n                \r\n                if utility > best_utility:\r\n                    best_utility = utility\r\n                    best_action = action\r\n        \r\n        return best_action\n"})}),"\n",(0,t.jsx)(e.h4,{id:"goal-directed-selection",children:"Goal-Directed Selection"}),"\n",(0,t.jsx)(e.p,{children:"Actions are selected based on how well they contribute to achieving goals:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"class GoalDirectedPlanner:\r\n    def __init__(self, actions):\r\n        self.actions = actions\r\n    \r\n    def select_action(self, state, goals):\r\n        applicable_actions = [a for a in self.actions if a.applicable(state)]\r\n        \r\n        # Rank actions by goal relevance\r\n        goal_relevance = {}\r\n        for action in applicable_actions:\r\n            relevance = 0\r\n            for goal in goals:\r\n                if goal in action.add_effects:\r\n                    relevance += 1\r\n                elif goal in action.del_effects:\r\n                    relevance -= 10  # Strong penalty for removing goals\r\n            goal_relevance[action] = relevance\r\n        \r\n        # Return action with highest relevance\r\n        return max(applicable_actions, key=lambda a: goal_relevance[a])\n"})}),"\n",(0,t.jsx)(e.h2,{id:"planning-algorithms",children:"Planning Algorithms"}),"\n",(0,t.jsx)(e.h3,{id:"forward-search-progression-planning",children:"Forward Search (Progression Planning)"}),"\n",(0,t.jsx)(e.p,{children:"Forward search explores states by applying actions forward from the initial state:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"def forward_search(initial_state, goal_test, actions, max_steps=100):\r\n    from collections import deque\r\n    \r\n    queue = deque([(initial_state, [])])  # (state, plan)\r\n    visited = set()\r\n    \r\n    while queue:\r\n        state, plan = queue.popleft()\r\n        \r\n        if goal_test(state):\r\n            return plan\r\n        \r\n        if len(plan) >= max_steps:\r\n            continue\r\n            \r\n        state_tuple = tuple(sorted(state))\r\n        if state_tuple in visited:\r\n            continue\r\n        visited.add(state_tuple)\r\n        \r\n        for action in actions:\r\n            if action.applicable(state):\r\n                new_state = action.apply(state)\r\n                new_plan = plan + [action]\r\n                queue.append((new_state, new_plan))\r\n    \r\n    return None  # No plan found\n"})}),"\n",(0,t.jsx)(e.h3,{id:"backward-search-regression-planning",children:"Backward Search (Regression Planning)"}),"\n",(0,t.jsx)(e.p,{children:"Backward search works from the goal state backward to the initial state:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"def backward_search(initial_state, goal_state, actions):\r\n    # This is a simplified version - full implementation is more complex\r\n    def regress(goal_state, action):\r\n        # Find a state that could lead to goal_state through action\r\n        # This requires inverting action effects\r\n        pass\r\n    \r\n    # Implementation would involve finding actions that could achieve goal_state\r\n    # then regressing to find states that could achieve the action's preconditions\r\n    pass\n"})}),"\n",(0,t.jsx)(e.h3,{id:"graphplan",children:"Graphplan"}),"\n",(0,t.jsx)(e.p,{children:"Graphplan builds a planning graph and searches for a solution level by level:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"class GraphPlan:\r\n    def __init__(self, actions, initial_state, goal_state):\r\n        self.actions = actions\r\n        self.initial_state = initial_state\r\n        self.goal_state = goal_state\r\n        self.layers = []\r\n    \r\n    def build_graph(self):\r\n        # Build planning graph layer by layer\r\n        level = 0\r\n        current_state = self.initial_state\r\n        \r\n        while True:\r\n            # Add propositions and actions to the level\r\n            # Check for mutex relationships\r\n            # Stop when goal can be achieved or graph levels off\r\n            break\r\n    \r\n    def extract_plan(self):\r\n        # Extract plan from the graph\r\n        pass\n"})}),"\n",(0,t.jsx)(e.h2,{id:"reactive-planning",children:"Reactive Planning"}),"\n",(0,t.jsx)(e.h3,{id:"deliberative-vs-reactive-systems",children:"Deliberative vs. Reactive Systems"}),"\n",(0,t.jsx)(e.p,{children:"Cognitive robots often combine deliberate planning with reactive behaviors:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"class ReactivePlanner:\r\n    def __init__(self, high_level_planner):\r\n        self.high_level_planner = high_level_planner\r\n        self.current_plan = []\r\n        self.current_step = 0\r\n    \r\n    def execute_step(self, state, sensor_data):\r\n        # Check for emergencies requiring immediate response\r\n        if self.detect_emergency(sensor_data):\r\n            return self.emergency_response(sensor_data)\r\n        \r\n        # Check if current plan needs replanning\r\n        if not self.plan_valid(state):\r\n            self.current_plan = self.high_level_planner.plan(state)\r\n            self.current_step = 0\r\n        \r\n        # Execute next step in plan\r\n        if self.current_step < len(self.current_plan):\r\n            action = self.current_plan[self.current_step]\r\n            self.current_step += 1\r\n            return action\r\n        else:\r\n            return None  # Plan completed\r\n    \r\n    def detect_emergency(self, sensor_data):\r\n        # Check for obstacles, system failures, etc.\r\n        return False\r\n    \r\n    def emergency_response(self, sensor_data):\r\n        # Return emergency action\r\n        return None\n"})}),"\n",(0,t.jsx)(e.h2,{id:"multi-level-planning",children:"Multi-Level Planning"}),"\n",(0,t.jsx)(e.h3,{id:"integration-of-different-planning-levels",children:"Integration of Different Planning Levels"}),"\n",(0,t.jsx)(e.p,{children:"Robots need to coordinate planning at different levels:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"class MultiLevelPlanner:\r\n    def __init__(self):\r\n        self.task_planner = HTNPlanner()\r\n        self.motion_planner = RRTPlanner()\r\n        self.action_planner = UtilityBasedPlanner()\r\n    \r\n    def plan(self, high_level_goal, environment_map):\r\n        # Task Planning\r\n        subtasks = self.task_planner.plan(high_level_goal)\r\n        \r\n        full_plan = []\r\n        current_location = self.get_robot_location()\r\n        \r\n        for subtask in subtasks:\r\n            # Motion Planning to reach subtask location\r\n            path = self.motion_planner.plan(current_location, subtask.location)\r\n            \r\n            # Action Planning for subtask execution\r\n            actions = self.action_planner.plan(subtask.description)\r\n            \r\n            full_plan.extend(path)\r\n            full_plan.extend(actions)\r\n            \r\n            current_location = subtask.location\r\n        \r\n        return full_plan\n"})}),"\n",(0,t.jsx)(e.h2,{id:"planning-under-uncertainty",children:"Planning under Uncertainty"}),"\n",(0,t.jsx)(e.h3,{id:"probabilistic-planning",children:"Probabilistic Planning"}),"\n",(0,t.jsx)(e.p,{children:"When the environment is partially observable or actions have uncertain outcomes:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"class ProbabilisticAction:\r\n    def __init__(self, name, preconditions, effects_with_probability):\r\n        self.name = name\r\n        self.preconditions = preconditions\r\n        # effects_with_probability: list of (effects, probability) tuples\r\n        self.effects_with_probability = effects_with_probability\r\n\r\nclass ProbabilisticPlanner:\r\n    def __init__(self, actions, initial_belief_state, goal_state):\r\n        self.actions = actions\r\n        self.initial_belief_state = initial_belief_state\r\n        self.goal_state = goal_state\r\n    \r\n    def plan(self):\r\n        # Use algorithms like POMCP (Partially Observable Monte Carlo Planning)\r\n        pass\n"})}),"\n",(0,t.jsx)(e.h3,{id:"contingent-planning",children:"Contingent Planning"}),"\n",(0,t.jsx)(e.p,{children:"Contingent planning accounts for observations during execution:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"class ContingentPlan:\r\n    def __init__(self):\r\n        self.plan_tree = {}  # Maps observations to actions\r\n    \r\n    def execute_with_feedback(self, initial_state):\r\n        state = initial_state\r\n        plan_node = self.plan_tree\r\n        \r\n        while not self.is_terminal(plan_node):\r\n            if self.is_action_node(plan_node):\r\n                action = plan_node['action']\r\n                result = self.execute_action(action, state)\r\n                \r\n                # Update state based on action result\r\n                state = self.update_state(state, action, result)\r\n                \r\n                # Select next node based on observation\r\n                next_observation = self.get_observation(state)\r\n                plan_node = plan_node['branches'][next_observation]\r\n            else:\r\n                # Wait for observation\r\n                observation = self.get_observation(state)\r\n                plan_node = plan_node[observation]\n"})}),"\n",(0,t.jsx)(e.h2,{id:"planning-in-dynamic-environments",children:"Planning in Dynamic Environments"}),"\n",(0,t.jsx)(e.h3,{id:"replanning-strategies",children:"Replanning Strategies"}),"\n",(0,t.jsx)(e.p,{children:"Robots operating in dynamic environments need to replan frequently:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"class DynamicPlanner:\r\n    def __init__(self, base_planner, replan_threshold=0.5):\r\n        self.base_planner = base_planner\r\n        self.replan_threshold = replan_threshold\r\n        self.current_plan = None\r\n        self.plan_age = 0\r\n    \r\n    def update_and_execute(self, state, environment_changes):\r\n        # If environment changed significantly, replan\r\n        if self.environment_changed_significantly(environment_changes):\r\n            self.current_plan = self.base_planner.plan(state)\r\n            self.plan_age = 0\r\n        else:\r\n            self.plan_age += 1\r\n        \r\n        # If plan is too old, replan\r\n        if self.plan_age > 10:  # Arbitrary threshold\r\n            self.current_plan = self.base_planner.plan(state)\r\n            self.plan_age = 0\r\n        \r\n        return self.execute_next_step(state, self.current_plan)\r\n    \r\n    def environment_changed_significantly(self, changes):\r\n        # Determine if changes require replanning\r\n        return any(change.impact > self.replan_threshold for change in changes)\n"})}),"\n",(0,t.jsx)(e.h2,{id:"cognitive-architecture-integration",children:"Cognitive Architecture Integration"}),"\n",(0,t.jsx)(e.h3,{id:"planning-in-cognitive-architectures",children:"Planning in Cognitive Architectures"}),"\n",(0,t.jsx)(e.p,{children:"Planning modules integrate with other cognitive modules:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"class CognitiveRobot:\r\n    def __init__(self):\r\n        # Perception module\r\n        self.perception = PerceptionModule()\r\n        \r\n        # Memory module\r\n        self.memory = MemoryModule()\r\n        \r\n        # Planning module\r\n        self.planner = MultiLevelPlanner()\r\n        \r\n        # Execution module\r\n        self.executor = ActionExecutor()\r\n    \r\n    def step(self, sensor_data, goals):\r\n        # Perceive environment\r\n        world_state = self.perception.process_sensors(sensor_data)\r\n        \r\n        # Update memory\r\n        self.memory.update(world_state)\r\n        \r\n        # Plan next action\r\n        plan = self.planner.plan(goals, world_state, self.memory.get_context())\r\n        \r\n        # Execute plan\r\n        action = self.executor.select_action(plan)\r\n        return action\n"})}),"\n",(0,t.jsx)(e.h2,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,t.jsx)(e.h3,{id:"planning-efficiency",children:"Planning Efficiency"}),"\n",(0,t.jsx)(e.p,{children:"Planning algorithms need to be efficient for real-time operation:"}),"\n",(0,t.jsx)(e.h4,{id:"heuristic-functions",children:"Heuristic Functions"}),"\n",(0,t.jsx)(e.p,{children:"Good heuristics can dramatically improve planning speed:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"def heuristic_distance(state, goal):\r\n    # Manhattan distance for grid-based planning\r\n    return abs(state.x - goal.x) + abs(state.y - goal.y)\r\n\r\ndef heuristic_manipulation(state, goal):\r\n    # For manipulation tasks, consider joint angles and object positions\r\n    joint_diff = sum(abs(j1 - j2) for j1, j2 in zip(state.joint_angles, goal.joint_angles))\r\n    object_diff = distance(state.object_pose, goal.object_pose)\r\n    return joint_diff + object_diff\n"})}),"\n",(0,t.jsx)(e.h4,{id:"plan-repair",children:"Plan Repair"}),"\n",(0,t.jsx)(e.p,{children:"Instead of replanning from scratch, modify existing plans:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"def repair_plan(current_plan, new_constraints):\r\n    # Identify part of plan affected by new constraints\r\n    affected_idx = find_affected_step(current_plan, new_constraints)\r\n    \r\n    # Repair from affected step onwards\r\n    if affected_idx is not None:\r\n        repaired_suffix = replan_from_step(current_plan[:affected_idx], new_constraints)\r\n        return current_plan[:affected_idx] + repaired_suffix\r\n    else:\r\n        return current_plan  # No repair needed\n"})}),"\n",(0,t.jsx)(e.h2,{id:"real-world-applications",children:"Real-World Applications"}),"\n",(0,t.jsx)(e.h3,{id:"service-robotics",children:"Service Robotics"}),"\n",(0,t.jsx)(e.p,{children:"Planning for service robots in human environments:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"class ServiceRobotPlanner:\r\n    def __init__(self):\r\n        self.task_planner = self.setup_service_task_planning()\r\n        self.social_awareness = SocialConstraintManager()\r\n    \r\n    def plan_delivery_task(self, start_location, destination, user_preferences):\r\n        # Consider social conventions (e.g., don't block doorways)\r\n        constraints = self.social_awareness.get_constraints(destination)\r\n        \r\n        # Plan path with social constraints\r\n        path = self.plan_path_with_constraints(start_location, destination, constraints)\r\n        \r\n        # Plan interaction with user\r\n        interaction = self.plan_user_interaction(user_preferences)\r\n        \r\n        return path + interaction\n"})}),"\n",(0,t.jsx)(e.h3,{id:"manufacturing-robotics",children:"Manufacturing Robotics"}),"\n",(0,t.jsx)(e.p,{children:"Industrial applications with strict timing requirements:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"class ManufacturingPlanner:\r\n    def __init__(self):\r\n        self.temporal_planner = TemporalPlanner()\r\n        self.quality_constraints = QualityConstraintManager()\r\n    \r\n    def plan_assembly_task(self, components, target_product, time_limit):\r\n        # Create temporal plan with resource constraints\r\n        plan = self.temporal_planner.create_plan(\r\n            actions=self.get_assembly_actions(components),\r\n            resource_limits=self.get_robotic_resources(),\r\n            deadline=time_limit\r\n        )\r\n        \r\n        # Add quality checks to plan\r\n        plan_with_checks = self.add_quality_checks(plan, self.quality_constraints)\r\n        \r\n        return plan_with_checks\n"})}),"\n",(0,t.jsx)(e.h2,{id:"challenges-and-future-directions",children:"Challenges and Future Directions"}),"\n",(0,t.jsx)(e.h3,{id:"scalability-challenges",children:"Scalability Challenges"}),"\n",(0,t.jsx)(e.p,{children:"Planning algorithms face challenges as problem complexity increases:"}),"\n",(0,t.jsx)(e.h4,{id:"state-space-explosion",children:"State Space Explosion"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Exponential growth in possible states"}),"\n",(0,t.jsx)(e.li,{children:"Need for abstraction and approximation"}),"\n",(0,t.jsx)(e.li,{children:"Hierarchical approaches for manageability"}),"\n"]}),"\n",(0,t.jsx)(e.h4,{id:"real-time-requirements",children:"Real-Time Requirements"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Planning must complete within time constraints"}),"\n",(0,t.jsx)(e.li,{children:"Anytime algorithms that improve over time"}),"\n",(0,t.jsx)(e.li,{children:"Approximate solutions when optimal planning is infeasible"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"integration-challenges",children:"Integration Challenges"}),"\n",(0,t.jsx)(e.h4,{id:"perception-action-loops",children:"Perception-Action Loops"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Tight integration between perception and planning"}),"\n",(0,t.jsx)(e.li,{children:"Handling uncertainty and partial observability"}),"\n",(0,t.jsx)(e.li,{children:"Robustness to perception errors"}),"\n"]}),"\n",(0,t.jsx)(e.h4,{id:"human-robot-interaction",children:"Human-Robot Interaction"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Planning that considers human behavior"}),"\n",(0,t.jsx)(e.li,{children:"Shared autonomy systems"}),"\n",(0,t.jsx)(e.li,{children:"Plan explanation and transparency"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"exercises",children:"Exercises"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Implement a simple STRIPS planner for a robot that needs to navigate and manipulate objects."}),"\n",(0,t.jsx)(e.li,{children:"Create a hierarchical task network for a robot housekeeping task."}),"\n",(0,t.jsx)(e.li,{children:"Design a reactive planning system that can replan when obstacles are detected."}),"\n",(0,t.jsx)(e.li,{children:"Implement a utility-based action selection system for a multi-goal scenario."}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"quiz",children:"Quiz"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"What does HTN stand for in planning paradigms?"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"A) Hierarchical Task Network"}),"\n",(0,t.jsx)(e.li,{children:"B) High-level Task Navigation"}),"\n",(0,t.jsx)(e.li,{children:"C) Human Task Normalization"}),"\n",(0,t.jsx)(e.li,{children:"D) Hardware Task Network"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Which planning approach works backwards from a goal to the initial state?"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"A) Forward search"}),"\n",(0,t.jsx)(e.li,{children:"B) Backward search"}),"\n",(0,t.jsx)(e.li,{children:"C) Anytime planning"}),"\n",(0,t.jsx)(e.li,{children:"D) Reactive planning"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"What is a key characteristic of contingent planning?"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"A) Plans are fixed at the beginning"}),"\n",(0,t.jsx)(e.li,{children:"B) Plans account for potential observations during execution"}),"\n",(0,t.jsx)(e.li,{children:"C) Plans ignore environmental changes"}),"\n",(0,t.jsx)(e.li,{children:"D) Plans use random action selection"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"reflection",children:"Reflection"}),"\n",(0,t.jsx)(e.p,{children:"Consider how cognitive planning bridges the gap between high-level goals and low-level robot control. What are the trade-offs between optimal planning and real-time requirements in robotic systems? How might planning algorithms need to evolve to handle increasingly complex real-world tasks? What role does uncertainty play in cognitive planning, and how can robots make robust decisions despite imperfect knowledge of their environment?"})]})}function p(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>s,x:()=>l});var t=i(6540);const a={},r=t.createContext(a);function s(n){const e=t.useContext(r);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:s(n.components),t.createElement(r.Provider,{value:e},n.children)}}}]);